{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fab873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scp\n",
    "import sklearn.neighbors\n",
    "import time\n",
    "from data_utils import load_dataset\n",
    "\n",
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d26084",
   "metadata": {},
   "source": [
    "Below are the 3 regression datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac339ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test = load_dataset('mauna_loa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test = load_dataset('rosenbrock', n_train=1000, d=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d9778",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test = load_dataset('pumadyn32nm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097e696",
   "metadata": {},
   "source": [
    "Below is an implementation of the kNN algorithm for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c5b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, implement distance metric as separate function\n",
    "def minkowski_dists(x_train, x_test_i, l=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns Minkowski distance between each element\n",
    "    of x_train and x_test_i as a (D,1) np array\n",
    "    \n",
    "    x_train is a (D,n) array\n",
    "    x_test_i is a (n,) array\n",
    "    \n",
    "    dists is a (D,1) array\n",
    "    \"\"\"\n",
    "    \n",
    "    p = l\n",
    "    x_test_i = x_test_i.reshape((1,-1)) # converts x_test_i to a (1,n) array\n",
    "    # not necessary... will still work w/out this b/c broadcasting\n",
    "    diff = np.abs(x_train-x_test_i)\n",
    "    power = np.power(diff,p)\n",
    "    sigma = np.sum(power,axis=1).reshape((x_train.shape[0],-1)) # axis = 1 --> sum along rows\n",
    "    dists = np.power(sigma,1/p)\n",
    "    return dists\n",
    "\n",
    "def kNN_regress(x_train, y_train, x_test, k=1, l=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns y_test results corresponding to x_test inputs using kNN algorithm\n",
    "    \n",
    "    x_train is a (D,n) array\n",
    "    y_train is a (D,1) array (regression: single output)\n",
    "    x_test is a (T,n) array\n",
    "    \n",
    "    y_test is a (T,1) array (regression: single output)\n",
    "    \"\"\"\n",
    "    \n",
    "    num_test_points = x_test.shape[0]\n",
    "    y_test = np.empty((num_test_points,1),)\n",
    "    \n",
    "    # compute distances (for each test point)\n",
    "    # assume distance metric is the Minkowski distance\n",
    "    for i, x_test_i in enumerate(x_test):\n",
    "        dists = minkowski_dists(x_train, x_test_i,l)\n",
    "        partition = np.argpartition(dists,kth=k,axis=0) # returns indices of dists\n",
    "                                                        # axis = 0 --> partition along column\n",
    "        kNN = partition[:k]\n",
    "        y_test[i,0] = np.average(y_train[kNN,0])\n",
    "    \n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a9967b",
   "metadata": {},
   "source": [
    "Implementation of v-fold cross-validation with v = 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_fold_cross_validation_RMSE(x_train, y_train, N, k=1, max_l=2, v=5, testing_runtime=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Conducts cross validation on x_train and y_train with v folds\n",
    "    \n",
    "    x_train and y_train are (N,n) arrays\n",
    "    trains using kNN validation with k\n",
    "    repeats model with different minkowski distance metric with p up to max_l\n",
    "    \n",
    "    Returns the average RMSE across the folds and for each p up to max_l\n",
    "    RMSE_avg is a (1,max_l) array\n",
    "    \"\"\"\n",
    "    \n",
    "    # divide data into v equal folds\n",
    "    # split data into folds (by index)\n",
    "    idx = np.arange(N,dtype=int)\n",
    "    if (N%v != 0):\n",
    "        # as N is not be a perfect multiple of v, add in 'fake' numbers that will be cleaned later\n",
    "        extra = np.random.choice(idx, size=N%v, replace=False)\n",
    "        idx = np.delete(idx,extra)\n",
    "        idx = np.random.permutation(idx).reshape((v,-1))\n",
    "        temp = -1 * np.ones(idx.shape[0], dtype=int)\n",
    "        temp[:extra.shape[0]] = extra\n",
    "        temp = temp.reshape(idx.shape[0],1)\n",
    "        idx = np.hstack((idx,temp))\n",
    "    else:\n",
    "        idx = np.random.permutation(idx).reshape((v,-1))\n",
    "    \n",
    "    RMSE = np.empty((v,max_l))\n",
    "    \n",
    "    # train and test for each fold\n",
    "    for i in range(v):\n",
    "        ith_fold_idx = idx[i]\n",
    "        ith_fold_idx = [i for i in ith_fold_idx if i>=0]\n",
    "        training_idx = np.delete(idx, i, axis=0)\n",
    "        training_idx = training_idx.reshape(-1) # flatten the array\n",
    "        training_idx = [i for i in training_idx if i>=0]\n",
    "        \n",
    "        x_tr, y_tr = x_train[training_idx], y_train[training_idx]\n",
    "        x_val, y_val = x_train[ith_fold_idx], y_train[ith_fold_idx]\n",
    "        \n",
    "        for l in range(1,max_l+1,1):\n",
    "            y_test = kNN_regress(x_tr, y_tr, x_val, k=k, l=l)\n",
    "            RMSE[i,l-1] = np.sqrt(np.mean(np.square(y_val-y_test)))\n",
    "        \n",
    "    RMSE_avg = np.average(RMSE, axis=0)\n",
    "    \n",
    "    if not testing_runtime:\n",
    "        print(\"k={}\".format(k))\n",
    "        for l in range(max_l):\n",
    "            print(\"\\tl={l}, RMSE={RMSE_avg}\".format(l=l+1, RMSE_avg=round(RMSE_avg[l], 6)))\n",
    "    \n",
    "    return RMSE_avg \n",
    "\n",
    "def estimate_best_param(x_train, y_train, v=5, max_l=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Estimates the best k and l values for optimal model results (i.e., tunes the model parameters)\n",
    "    Uses cross validation with v folds for tuning\n",
    "    Repeats training with different minkowski distance metric with p up to max_l\n",
    "    \n",
    "    x_train and y_train are (N,n) arrays\n",
    "    \n",
    "    Returns average RMSE across folds for each k up to sqrt(N) and for each p up to max_l\n",
    "    RMSE_avg is (sqrt(N),max_l) array\n",
    "    Returns best_k and best_l --> ints\n",
    "    \"\"\"\n",
    "    \n",
    "    # assume training data includes both training and validation sets\n",
    "    t0 = time.time()\n",
    "    print(\"Running...\")\n",
    "    \n",
    "    N = x_train.shape[0] # number of training points\n",
    "    k_max = int(np.sqrt(N)) # rule of thumb: k < sqrt(N)\n",
    "    RMSE_avg = np.empty((k_max,max_l)) # RMSE_avg[k][l] stores the average RMSE value for k, l distance metric\n",
    "    \n",
    "    # timing estimate\n",
    "    t0 = time.time()\n",
    "    print(\"Estimating running time...\")\n",
    "    v_fold_cross_validation_RMSE(x_train, y_train, N=N, k=k_max//2, max_l=max_l, v=v, testing_runtime=True)\n",
    "    print(\"Estimated running time: {}s\".format(round((time.time()-t0)*k_max,2)))\n",
    "    \n",
    "    # start parameter tuning\n",
    "    t0 = time.time()\n",
    "    print(\"Beginning parameter tuning...\")\n",
    "    \n",
    "    for k in range(1, k_max+1, 1):\n",
    "        RMSE_avg[k-1] = v_fold_cross_validation_RMSE(x_train, y_train, N=N, k=k, max_l=max_l, v=v)\n",
    "    \n",
    "    best_k, best_l = np.unravel_index(np.argmin(RMSE_avg), RMSE_avg.shape)\n",
    "    best_k += 1\n",
    "    best_l += 1\n",
    "    print(\"Best: k={}, l={}; with min avg RMSE={}\".format(best_k, best_l, round(RMSE_avg[best_k-1,best_l-1],6)))\n",
    "    print(\"took {}s\".format(round(time.time()-t0,2)))\n",
    "    return RMSE_avg, best_k, best_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4756784c",
   "metadata": {},
   "source": [
    "Run mauna_loa dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e51942",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test = load_dataset('mauna_loa')\n",
    "x_train = np.vstack([x_valid, x_train])\n",
    "y_train = np.vstack([y_valid, y_train])\n",
    "\n",
    "RMSE_avg, best_k, best_l = estimate_best_param(x_train, y_train, v=5, max_l=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe0f16",
   "metadata": {},
   "source": [
    "Use best k and l to test model and find test RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1922903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_RMSE(x_train, y_train, x_test, y_test, best_k, best_l):\n",
    "    # run model\n",
    "    y_predict = kNN_regress(x_train, y_train, x_test, k=best_k, l=best_l)\n",
    "    \n",
    "    # find RMSE between y_predict and y_test\n",
    "    RMSE_test = np.sqrt(np.mean(np.square(y_predict-y_test)))\n",
    "    \n",
    "    return RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_test = test_model_RMSE(x_train, y_train, x_test, y_test, best_k, best_l)\n",
    "print(\"RMSE of model on test data for k={k} and l={l}: {RMSE_test}\".format(k=best_k, l=best_l, RMSE_test=RMSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8ea4ab",
   "metadata": {},
   "source": [
    "RMSE vs k plot for mauna_loa dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc1b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Average Cross Validation RMSE vs k for l_2 (mauna_loa dataset)\")\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Average RMSE')\n",
    "k_max = int(np.sqrt(x_train.shape[0]))\n",
    "l = 2\n",
    "x_axis = np.arange(k_max) + 1\n",
    "y_axis = RMSE_avg[:,l-1]\n",
    "plt.grid(visible=True)\n",
    "plt.xticks(range(min(x_axis), max(x_axis)+1))\n",
    "plt.plot(x_axis, y_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa565300",
   "metadata": {},
   "source": [
    "We see k = 2 is the location of min RMSE. However, we also have k = 24 as a local min. Let's plot the regression model predictions for both k = 2 and k = 24 and compare with the actual test targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Comparison of test predictions for k = 2, k = 24, and actual targets (l_2)\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Target (Output)\")\n",
    "plt.plot(x_test, y_test, label='actual')\n",
    "y_predict_k2 = kNN_regress(x_train, y_train, x_test, k=2, l=2)\n",
    "y_predict_k24 = kNN_regress(x_train, y_train, x_test, k=24, l=2)\n",
    "plt.plot(x_test, y_predict_k2, label=\"k=2\")\n",
    "plt.plot(x_test, y_predict_k24, label=\"k=24\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad3819f",
   "metadata": {},
   "source": [
    "As we can see, the predictions for both k = 2 and k = 24 are not close at all, not even the behaviour of the data is captured. k = 24 is slightly closer to the actual targets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dbdfb3",
   "metadata": {},
   "source": [
    "Let's also plot the regression model for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d45762",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Comparison of training predictions for k = 2, k = 24, and actual targets (l_2)\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Target (Output)\")\n",
    "plt.plot(x_train, y_train, label='actual')\n",
    "y_predict_k2 = kNN_regress(x_train, y_train, x_train, k=2, l=2)\n",
    "y_predict_k24 = kNN_regress(x_train, y_train, x_train, k=24, l=2)\n",
    "plt.plot(x_train, y_predict_k2, label=\"k=2\")\n",
    "plt.plot(x_train, y_predict_k24, label=\"k=24\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800e5ae9",
   "metadata": {},
   "source": [
    "As we can see, the model for k = 2 overfits the training data and the model for k = 24 underfits the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b531bf12",
   "metadata": {},
   "source": [
    "Run rosenbrock dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd9935",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test = load_dataset('rosenbrock', n_train=1000, d=2)\n",
    "x_train = np.vstack([x_valid, x_train])\n",
    "y_train = np.vstack([y_valid, y_train])\n",
    "\n",
    "RMSE_avg, best_k, best_l = estimate_best_param(x_train, y_train, v=5, max_l=2)\n",
    "RMSE_test = test_model_RMSE(x_train, y_train, x_test, y_test, best_k, best_l)\n",
    "print(\"RMSE of model on test data for k={k} and l={l}: {RMSE_test}\".format(k=best_k, l=best_l, RMSE_test=RMSE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452afe6a",
   "metadata": {},
   "source": [
    "Run pumadyn32nm dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test = load_dataset('pumadyn32nm')\n",
    "x_train = np.vstack([x_valid, x_train])\n",
    "y_train = np.vstack([y_valid, y_train])\n",
    "\n",
    "RMSE_avg, best_k, best_l = estimate_best_param(x_train, y_train, v=5, max_l=2)\n",
    "RMSE_test = test_model_RMSE(x_train, y_train, x_test, y_test, best_k, best_l)\n",
    "print(\"RMSE of model on test data for k={k} and l={l}: {RMSE_test}\".format(k=best_k, l=best_l, RMSE_test=RMSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbbe7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
